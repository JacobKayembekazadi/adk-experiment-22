# ğŸ¤– Local Multi-Agent Collaborative Intelligence System

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-1.46%2B-red.svg)](https://streamlit.io)
[![Ollama](https://img.shields.io/badge/Ollama-Local%20LLM-green.svg)](https://ollama.com)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **A production-ready framework that orchestrates multiple AI agents to collaboratively solve complex problems through a structured 4-phase workflow - completely local, private, and cost-effective.**

## ğŸŒŸ Key Features

### ğŸ§  **Multi-Agent Intelligence**

- **5 Specialized AI Agents** with distinct roles and personalities
- **Concurrent Processing** for optimal performance
- **Structured 4-Phase Collaboration** workflow
- **Consensus Building** with confidence weighting

### ğŸ  **Local-First Architecture**

- **100% Local Operation** - No cloud dependencies
- **Complete Data Privacy** - Your data never leaves your machine
- **Cost Effective** - No API fees or usage limits
- **Enterprise Ready** - Production-grade reliability and monitoring

### ğŸ¨ **Dual Interface**

- **Modern Web Application** - Streamlit-based dashboard with real-time monitoring
- **Powerful CLI** - Command-line interface for automation and scripting
- **Interactive Mode** - Conversational problem-solving interface

### ğŸ”§ **Production Features**

- **Robust Error Handling** with multiple fallback strategies
- **Comprehensive Metrics** and performance monitoring
- **Session Persistence** with complete history tracking
- **Configuration Management** with presets and customization
- **Async Processing** for maximum throughput

---

## ğŸš€ Quick Start

### ğŸ“‹ Prerequisites

1. **Install Ollama** from [ollama.com](https://ollama.com)
2. **Download Required Models**:

   ```bash
   ollama pull llama3.2:3b
   ollama pull deepseek-r1:latest
   ollama serve
   ```

3. **Verify Installation**:

   ```bash
   curl http://localhost:11434/api/tags
   ```

### âš¡ Installation

```bash
# Clone the repository
git clone https://github.com/JacobKayembekazadi/adk-experiment-22.git
cd adk-experiment-22/local_agent_system

# Install dependencies
pip install -r requirements.txt

# Test system connectivity
python main.py --test

# Launch web interface
python run_streamlit.py
```

### ğŸ¯ First Problem

**Web Interface** (Recommended):

1. Open <http://localhost:8501> in your browser
2. Enter your problem in the collaboration interface
3. Watch real-time collaboration unfold!

**Command Line**:

```bash
python main.py --problem "How can we improve customer retention for a SaaS product?"
```

---

## ğŸ—ï¸ System Architecture

### ğŸ¤– The Agent Team

| Agent | Role | Model | Temperature | Specialty |
|-------|------|-------|-------------|-----------|
| **DataScientist_Alpha** | Data Scientist | llama3.2:3b | 0.3 | Analytical & methodical analysis |
| **ProductManager_Beta** | Product Manager | llama3.2:3b | 0.5 | User-focused & strategic thinking |
| **TechArchitect_Gamma** | Technical Architect | deepseek-r1:latest | 0.4 | System design & implementation |
| **CreativeInnovator_Delta** | Creative Innovator | llama3.2:3b | 0.8 | Bold & unconventional ideas |
| **RiskAnalyst_Epsilon** | Risk Analyst | llama3.2:3b | 0.2 | Cautious & thorough evaluation |

### ğŸ”„ 4-Phase Collaboration Workflow

```mermaid
graph LR
    A[ğŸ“ Individual Analysis] --> B[ğŸ” Cross-Agent Critique]
    B --> C[ğŸ”¬ Solution Synthesis] --> D[ğŸ¯ Consensus Building]
    
    style A fill:#e1f5fe
    style B fill:#f3e5f5
    style C fill:#e8f5e8
    style D fill:#fff3e0
```

1. **ğŸ“ Individual Analysis** - All agents analyze the problem concurrently
2. **ğŸ” Cross-Agent Critique** - Round-robin critique and feedback
3. **ğŸ”¬ Solution Synthesis** - Synthesis of insights from all perspectives
4. **ğŸ¯ Consensus Building** - Algorithmic consensus with confidence scoring

### ğŸ›ï¸ Technical Architecture

```mermaid
graph TB
    subgraph "ğŸŒ User Interfaces"
        WEB[Web Dashboard<br/>Streamlit]
        CLI[CLI Interface<br/>main.py]
    end
    
    subgraph "ğŸ§  Core System"
        COLLAB[Collaboration Engine<br/>LocalAgent2AgentSystem]
        CONFIG[Configuration Manager]
        METRICS[Metrics & Monitoring]
    end
    
    subgraph "ğŸ¤– Agent Layer"
        AGENTS[5 Specialized Agents]
    end
    
    subgraph "ğŸ  Local Infrastructure"
        OLLAMA[Ollama Server<br/>LLM Inference]
        STORAGE[File System<br/>Sessions & Config]
    end
    
    WEB --> COLLAB
    CLI --> COLLAB
    COLLAB --> CONFIG
    COLLAB --> METRICS
    COLLAB --> AGENTS
    AGENTS --> OLLAMA
    CONFIG --> STORAGE
    METRICS --> STORAGE
```

---

## ğŸ’» Usage Guide

### ğŸŒ Web Interface (Recommended)

The Streamlit web application provides the most intuitive experience:

```bash
# Start the web application
python run_streamlit.py

# Open browser to http://localhost:8501
```

**Features:**
- ğŸ“Š **Real-time Dashboard** - Watch collaboration progress live
- ğŸ“ˆ **Performance Metrics** - Visualize timing and success rates
- ğŸ“‹ **Session History** - Browse and export past collaborations
- âš™ï¸ **Configuration Panel** - Adjust agent settings and parameters
- ğŸ“± **Mobile Responsive** - Works on all device sizes

### ğŸ’» Command Line Interface

Perfect for automation, scripting, and power users:

#### Basic Commands

```bash
# Test system health
python main.py --test

# Solve a specific problem
python main.py --problem "Your problem statement here"

# Interactive mode for multiple problems
python main.py --interactive

# Run example scenarios
python main.py --examples

# Verbose output for debugging
python main.py --problem "Your problem" --verbose
```

#### Advanced Options

```bash
# Use configuration presets
python main.py --preset light --problem "Your problem"
python main.py --preset balanced --problem "Your problem"
python main.py --preset premium --problem "Your problem"

# Custom configuration file
python main.py --config custom_config.yaml --problem "Your problem"

# System information
python main.py --list-presets
python main.py --config-info
```

### ğŸ¯ Example Session

```bash
$ python main.py --problem "How should a startup approach scaling from 10 to 100 employees?"

ğŸ”„ Running 4-phase collaboration...
âœ… Phase 1: Individual Analysis completed (12.3s)
âœ… Phase 2: Cross-Agent Critique completed (18.7s)  
âœ… Phase 3: Solution Synthesis completed (14.2s)
âœ… Phase 4: Consensus Building completed (0.8s)

ğŸ¯ FINAL CONSENSUS (Confidence: 0.87):
Based on comprehensive multi-agent analysis, scaling from 10 to 100 employees 
requires a systematic approach across three critical dimensions:

1. **Organizational Structure**: Implement clear hierarchies and departments
2. **Process Systematization**: Establish scalable workflows and documentation  
3. **Culture Preservation**: Maintain startup agility while adding structure

ğŸ’¡ Key Insights:
â€¢ Hire middle management before reaching 30 employees
â€¢ Implement HR systems and processes early
â€¢ Create clear communication channels and decision-making frameworks
â€¢ Establish performance management and career development paths

â¡ï¸ Next Action: Develop a 6-month scaling roadmap with specific milestones

ğŸ‘¥ Contributing Agents: All 5 agents provided insights
ğŸ“Š Session saved as: session_20250807_143022_abc123.json
```

---

## âš™ï¸ Configuration

### ğŸ›ï¸ Configuration Presets

The system includes three built-in presets:

| Preset | Performance | Resource Usage | Best For |
|--------|-------------|----------------|----------|
| **Light** | Fast | Low | Quick testing, limited resources |
| **Balanced** | Good | Medium | Most use cases, default option |
| **Premium** | Best | High | Complex problems, maximum quality |

### ğŸ“ Custom Configuration

Create your own `config.yaml`:

```yaml
system:
  ollama_base_url: "http://localhost:11434"
  ollama_timeout: 120
  max_retries: 3
  log_level: "INFO"
  session_save_dir: "./sessions"
  enable_metrics: true

agents:
  - agent_id: "DataScientist_Alpha"
    role: "Data Scientist"
    model_name: "llama3.2:3b"
    temperature: 0.3
    enabled: true
    personality: "analytical/methodical"
    system_prompt: "Your custom prompt here..."
```

### ğŸ”§ Agent Customization

Each agent can be customized:
- **Model Assignment**: Choose different Ollama models
- **Temperature Settings**: Control creativity vs. consistency
- **System Prompts**: Define agent behavior and expertise
- **Enable/Disable**: Control which agents participate

---

## ğŸ“Š Output & Results

### ğŸ“ˆ Real-time Monitoring

The web interface provides:
- **Live Progress Tracking** - See which agents are working
- **Performance Metrics** - Response times and success rates
- **Confidence Visualization** - Chart consensus building
- **Agent Activity** - Individual agent contributions

### ğŸ“„ Session Data

Each collaboration generates:

**Structured Results**:
```json
{
  "session_id": "20250807_143022_abc123",
  "problem_statement": "Your problem...",
  "final_consensus": {
    "main_response": "Comprehensive solution...",
    "confidence_level": 0.87,
    "key_insights": ["insight1", "insight2"],
    "next_action": "Recommended next step",
    "contributing_agents": ["all"]
  },
  "metrics": {
    "total_duration": 45.8,
    "phase_durations": {...},
    "success_rate": 1.0
  }
}
```

**Export Options**:
- ğŸ“‹ **JSON**: Complete session data
- ğŸ“Š **CSV**: Metrics and performance data
- ğŸ“ **Markdown**: Human-readable summary
- ğŸ“ˆ **Charts**: Performance visualizations

---

## ğŸ—ï¸ Project Structure

```text
local_agent_system/
â”œâ”€â”€ ğŸŒ Frontend
â”‚   â”œâ”€â”€ streamlit_app.py          # Web application
â”‚   â”œâ”€â”€ run_streamlit.py          # Startup script
â”‚   â””â”€â”€ .streamlit/config.toml    # Web config
â”œâ”€â”€ ğŸ§  Core System
â”‚   â”œâ”€â”€ collaboration/
â”‚   â”‚   â””â”€â”€ system.py             # Main orchestrator
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ base_agent.py         # Abstract base
â”‚   â”‚   â””â”€â”€ local_agent.py        # Ollama integration
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ config_manager.py     # Configuration system
â”‚       â”œâ”€â”€ agent_config.yaml     # Agent definitions
â”‚       â””â”€â”€ presets/              # Configuration presets
â”œâ”€â”€ ğŸ› ï¸ Utilities
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ ollama_client.py      # Async Ollama client
â”‚       â”œâ”€â”€ response_parser.py    # JSON parsing
â”‚       â””â”€â”€ streamlit_helpers.py  # Web utilities
â”œâ”€â”€ ğŸ—‚ï¸ Data
â”‚   â””â”€â”€ sessions/                 # Session history
â”œâ”€â”€ ğŸ§ª Testing
â”‚   â””â”€â”€ tests/                    # Test suite
â””â”€â”€ ğŸ“š Documentation
    â”œâ”€â”€ README.md                 # This file
    â”œâ”€â”€ architectural_document.md # Technical architecture
    â””â”€â”€ STREAMLIT_README.md       # Web interface guide
```

---

## ğŸ”§ Advanced Topics

### ğŸš€ Performance Optimization

**Typical Performance**:
- **Phase 1**: 10-30 seconds (concurrent)
- **Phase 2**: 15-45 seconds (sequential)  
- **Phase 3**: 10-30 seconds (concurrent)
- **Phase 4**: <1 second (algorithmic)
- **Total**: 35-106 seconds

**Optimization Tips**:
- Use `light` preset for faster results
- Reduce agent count for simpler problems
- Increase timeout for complex problems
- Monitor memory usage with large models

### ğŸ”Œ Extending the System

**Add New Agents**:
1. Define agent in `agent_config.yaml`
2. Specify model, temperature, and prompts
3. System automatically loads new agents

**Custom Models**:
1. Download model: `ollama pull your-model`
2. Update agent configuration
3. Test with `python main.py --test`

**Integration APIs**:
- The system can be imported as a Python module
- REST API wrapper available (future enhancement)
- Session data can be consumed by external systems

### ğŸ”’ Security & Privacy

**Local-First Security**:
- âœ… No external API calls
- âœ… Complete data sovereignty  
- âœ… No internet dependency
- âœ… Standard OS file permissions

**Data Protection**:
- All processing happens locally
- Session data stored in local files
- No telemetry or usage tracking
- User controls all data retention

---

## ğŸ› ï¸ Troubleshooting

### Common Issues

#### ğŸ”Œ Connection Problems

**"Failed to connect to Ollama"**:
```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Start Ollama if needed
ollama serve

# Test connectivity
python main.py --test
```

#### ğŸ¤– Model Issues

**"Model not found"**:
```bash
# List available models
ollama list

# Download missing models
ollama pull llama3.2:3b
ollama pull deepseek-r1:latest

# Update configuration if needed
python main.py --config-info
```

#### ğŸŒ Web Interface Issues

**"Streamlit not starting"**:
```bash
# Install dependencies
pip install -r requirements.txt

# Start with checks
python run_streamlit.py

# Direct start (debugging)
streamlit run streamlit_app.py
```

#### ğŸ› Debug Mode

```bash
# Enable detailed logging
python main.py --problem "test" --verbose

# Check system status
python main.py --config-info

# Test individual components
python -c "from collaboration.system import LocalAgent2AgentSystem; print('Import OK')"
```

### Performance Issues

**Slow responses**:
- Use lighter models (`llama3.2:3b` vs larger models)
- Reduce temperature settings
- Use `light` preset configuration
- Check system resources (CPU, memory)

**Memory issues**:
- Close other applications
- Use smaller models
- Reduce concurrent agent count
- Monitor with `python main.py --config-info`

---

## ğŸ¯ Use Cases

### ğŸ’¼ Business Applications
- **Strategic Planning** - Multi-perspective business strategy
- **Product Development** - User-centered design decisions  
- **Risk Assessment** - Comprehensive risk analysis
- **Process Improvement** - Workflow optimization
- **Market Analysis** - Multi-faceted market research

### ğŸ”¬ Research & Development
- **Literature Review** - Multi-angle research synthesis
- **Problem Analysis** - Complex problem decomposition
- **Solution Design** - Innovative approach generation
- **Validation** - Multi-perspective evaluation
- **Documentation** - Comprehensive report generation

### ğŸ“ Education & Training
- **Case Study Analysis** - Multi-perspective case examination
- **Curriculum Development** - Educational content creation
- **Assessment Design** - Comprehensive evaluation methods
- **Learning Path Planning** - Personalized education strategies

### ğŸ—ï¸ Technical Projects
- **Architecture Review** - System design evaluation
- **Technology Selection** - Multi-criteria decision making
- **Code Review** - Comprehensive code analysis
- **Documentation** - Technical writing assistance
- **Troubleshooting** - Complex problem diagnosis

---

## ğŸ¤ Contributing

We welcome contributions! Here's how you can help:

### ğŸ› Bug Reports
- Use the GitHub Issues tracker
- Include system information and logs
- Provide steps to reproduce

### ğŸ’¡ Feature Requests  
- Describe the use case and benefit
- Consider backwards compatibility
- Provide implementation suggestions

### ğŸ”§ Code Contributions
1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Submit a pull request

### ğŸ“š Documentation
- Improve existing documentation
- Add examples and tutorials
- Translate to other languages

---

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Ollama Team** - For the excellent local LLM infrastructure
- **Streamlit** - For the amazing web framework
- **Python Community** - For the robust ecosystem
- **AI Research Community** - For advancing multi-agent collaboration

---

## ğŸ“ Support & Community

- ğŸ“§ **Issues**: [GitHub Issues](https://github.com/JacobKayembekazadi/adk-experiment-22/issues)
- ğŸ“– **Documentation**: [Project Wiki](https://github.com/JacobKayembekazadi/adk-experiment-22/wiki)
- ğŸ’¬ **Discussions**: [GitHub Discussions](https://github.com/JacobKayembekazadi/adk-experiment-22/discussions)

---

<div align="center">

**ğŸš€ Ready to experience the future of collaborative AI?**

[â¬‡ï¸ Get Started](#-quick-start) | [ğŸ“– View Architecture](architectural_document.md) | [ğŸŒ Try Web Demo](http://localhost:8501)

---

*Built with â¤ï¸ for the local-first AI community*

</div>
